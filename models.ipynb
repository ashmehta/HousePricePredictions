{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Price</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Living Space</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip Code Population</th>\n",
       "      <th>Zip Code Density</th>\n",
       "      <th>County</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>3999000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1967</td>\n",
       "      <td>74 GRAND ST APT 3</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>29563</td>\n",
       "      <td>20967.9</td>\n",
       "      <td>New York</td>\n",
       "      <td>370046.0</td>\n",
       "      <td>40.72001</td>\n",
       "      <td>-74.00472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>3999000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1967</td>\n",
       "      <td>74 GRAND ST APT 3</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>29563</td>\n",
       "      <td>20967.9</td>\n",
       "      <td>New York</td>\n",
       "      <td>370046.0</td>\n",
       "      <td>40.72001</td>\n",
       "      <td>-74.00472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10014</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>718</td>\n",
       "      <td>140 CHARLES ST APT 4D</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>29815</td>\n",
       "      <td>23740.9</td>\n",
       "      <td>New York</td>\n",
       "      <td>249880.0</td>\n",
       "      <td>40.73407</td>\n",
       "      <td>-74.00601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10014</td>\n",
       "      <td>760000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1538</td>\n",
       "      <td>38 JONES ST</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>29815</td>\n",
       "      <td>23740.9</td>\n",
       "      <td>New York</td>\n",
       "      <td>249880.0</td>\n",
       "      <td>40.73407</td>\n",
       "      <td>-74.00601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10014</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>81 BEDFORD ST APT 3F</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>29815</td>\n",
       "      <td>23740.9</td>\n",
       "      <td>New York</td>\n",
       "      <td>249880.0</td>\n",
       "      <td>40.73407</td>\n",
       "      <td>-74.00601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zip Code      Price  Beds  Baths  Living Space                Address  \\\n",
       "0     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
       "1     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
       "2     10014  1650000.0     1      1           718  140 CHARLES ST APT 4D   \n",
       "3     10014   760000.0     3      2          1538            38 JONES ST   \n",
       "4     10014  1100000.0     1      1           600   81 BEDFORD ST APT 3F   \n",
       "\n",
       "       City     State  Zip Code Population  Zip Code Density    County  \\\n",
       "0  New York  New York                29563           20967.9  New York   \n",
       "1  New York  New York                29563           20967.9  New York   \n",
       "2  New York  New York                29815           23740.9  New York   \n",
       "3  New York  New York                29815           23740.9  New York   \n",
       "4  New York  New York                29815           23740.9  New York   \n",
       "\n",
       "   Median Household Income  Latitude  Longitude  \n",
       "0                 370046.0  40.72001  -74.00472  \n",
       "1                 370046.0  40.72001  -74.00472  \n",
       "2                 249880.0  40.73407  -74.00601  \n",
       "3                 249880.0  40.73407  -74.00601  \n",
       "4                 249880.0  40.73407  -74.00601  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/akshitmehta/Desktop/HousePricePrediction/American_Housing_Data_20231209.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns not relevant to the model\n",
    "df_drop = df.drop(columns=['Address', 'City', 'State', 'Zip Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin preparing the pipelines for the models\n",
    "X = df_drop.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipelines for the models\n",
    "\n",
    "#defining the numerical and categorical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "#defining the numerical and categorical transformers\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), \n",
    "                                      ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#creating the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "Mean Squared Error: 510080968471.69934\n",
      "Mean Absolute Error: 263319.7164039078\n",
      "R-squared: 0.47298316927695416\n"
     ]
    }
   ],
   "source": [
    "#Defining Baseline Model\n",
    "\n",
    "# Create a pipeline for the baseline model\n",
    "baseline_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('regressor', LinearRegression())])\n",
    "\n",
    "# Train the baseline model\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_baseline = baseline_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"Baseline Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_baseline)\n",
    "print(\"Mean Absolute Error:\", mae_baseline)\n",
    "print(\"R-squared:\", r2_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Metrics:\n",
      "Mean Squared Error: 407600828907.0381\n",
      "Mean Absolute Error: 197022.64031716104\n",
      "R-squared: 0.5788658853626842\n"
     ]
    }
   ],
   "source": [
    "#Defining Decision Tree Model, random forest model and KNN model\n",
    "\n",
    "# Create a pipeline for the decision tree model\n",
    "decision_tree_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('regressor', DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "# Train the decision tree model\n",
    "decision_tree_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_decision_tree = decision_tree_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the decision tree model\n",
    "mse_decision_tree = mean_squared_error(y_test, y_pred_decision_tree)\n",
    "mae_decision_tree = mean_absolute_error(y_test, y_pred_decision_tree)\n",
    "r2_decision_tree = r2_score(y_test, y_pred_decision_tree)\n",
    "\n",
    "print(\"Decision Tree Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_decision_tree)\n",
    "print(\"Mean Absolute Error:\", mae_decision_tree)\n",
    "print(\"R-squared:\", r2_decision_tree)\n",
    "\n",
    "# Create a pipeline for the random forest model\n",
    "random_forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Train the random forest model\n",
    "random_forest_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_random_forest = random_forest_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the random forest model\n",
    "mse_random_forest = mean_squared_error(y_test, y_pred_random_forest)\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred_random_forest)\n",
    "r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
    "\n",
    "print(\"Random Forest Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_random_forest)\n",
    "print(\"Mean Absolute Error:\", mae_random_forest)\n",
    "print(\"R-squared:\", r2_random_forest)\n",
    "\n",
    "# Create a pipeline for the KNN model\n",
    "knn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', KNeighborsRegressor())])\n",
    "\n",
    "# Train the KNN model\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_knn)\n",
    "print(\"Mean Absolute Error:\", mae_knn)\n",
    "print(\"R-squared:\", r2_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a plot to compare the models\n",
    "\n",
    "model_names = ['Baseline', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "mse_values = [mse_baseline, mse_decision_tree, mse_random_forest, mse_knn]\n",
    "mae_values = [mae_baseline, mae_decision_tree, mae_random_forest, mae_knn]\n",
    "r2_values = [r2_baseline, r2_decision_tree, r2_random_forest, r2_knn]\n",
    "\n",
    "data = {'Model': model_names, 'MSE': mse_values, 'MAE': mae_values, 'R-squared': r2_values}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='MSE', data=df, ax=ax)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Mean Squared Error')\n",
    "ax.set_title('Mean Squared Error Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a plot to compare the models\n",
    "\n",
    "model_names = ['Baseline', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "mse_values = [mse_baseline, mse_decision_tree, mse_random_forest, mse_knn]\n",
    "mae_values = [mae_baseline, mae_decision_tree, mae_random_forest, mae_knn]\n",
    "r2_values = [r2_baseline, r2_decision_tree, r2_random_forest, r2_knn]\n",
    "\n",
    "data = {'Model': model_names, 'MSE': mse_values, 'MAE': mae_values, 'R-squared': r2_values}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='Model', y='R-squared', data=df, ax=ax)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('R-squared')\n",
    "ax.set_title('R-squared Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the random forest model \n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2']    \n",
    "}\n",
    "\n",
    "# Create a pipeline for the random forest model\n",
    "random_forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(random_forest_pipeline, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best model\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_random_forest = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the random forest model\n",
    "mse_random_forest = mean_squared_error(y_test, y_pred_random_forest)\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred_random_forest)    \n",
    "r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
    "\n",
    "print(\"Random Forest Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_random_forest)\n",
    "print(\"Mean Absolute Error:\", mae_random_forest)\n",
    "print(\"R-squared:\", r2_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building XGBoost model\n",
    "xgbr = xgb.XGBRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state = 42)\n",
    "# Create a pipeline for the XGBoost model\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', xgbr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and predict the XGBoost model\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_xgb)\n",
    "print(\"Mean Absolute Error:\", mae_xgb)\n",
    "print(\"R-squared:\", r2_xgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the XGBoost Model\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__min_child_weight': [1, 2, 3],\n",
    "    'regressor__gamma': [0, 0.1, 0.2],\n",
    "    'regressor__subsample': [0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create a pipeline for the XGBoost model\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', xgbr)])\n",
    "\n",
    "# Create a RandomizedSearchCV object    \n",
    "random_search = RandomizedSearchCV(xgb_pipeline, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best model\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)    \n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Model Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_xgb)\n",
    "print(\"Mean Absolute Error:\", mae_xgb)\n",
    "print(\"R-squared:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
